{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea1903-4b05-4749-99c8-4cfe245a355c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "import open3d as o3d\n",
    "\n",
    "def get_grid_points(chgcar):\n",
    "    grid = chgcar.data['total']\n",
    "    dims = grid.shape\n",
    "    return [np.array([i, j, k]) for i in np.linspace(0, 1, dims[0]) for j in np.linspace(0, 1, dims[1]) for k in np.linspace(0, 1, dims[2])]\n",
    "\n",
    "def grid_points_to_cartesian(lattice, grid_points):\n",
    "    return [lattice.get_cartesian_coords(gp) for gp in grid_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86c275-c6fb-4f14-989d-9a40dc7b36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"mp_id_data.json\", \"r\") as f:\n",
    "    dic = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bac97f-d19f-407b-9640-3515245df6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(file=tot[0], mode='rb') as f:\n",
    "    chrgecar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a94bc3-956d-4707-a1ec-5c370f77217c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = list(chrgecar.spin_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b8bd8-1657-4bc8-83f9-6121370da597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((cartesian_points, np.expand_dims(total_data, axis=1),  ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93949aa-50f8-40ae-8b6f-0ad6335f96b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1feat\n",
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "tot = glob.glob(\"/path/to/saved/*.pickle\")\n",
    "\n",
    "def make_np(i, dic):\n",
    "    #print(i)\n",
    "    with open(file=i, mode='rb') as f:\n",
    "        chrgecar = pickle.load(f)\n",
    "    chgcar = chrgecar\n",
    "    grid_points = get_grid_points(chgcar)\n",
    "    cartesian_points = grid_points_to_cartesian(chgcar.structure.lattice, grid_points)\n",
    "\n",
    "    total_data = chgcar.data['total'].flatten()/dic[i.split('/')[-1].split('.')[0]]['vol']\n",
    "    data = np.concatenate((cartesian_points, np.expand_dims(chgcar.data['total'].flatten(), axis=1)),axis=1)\n",
    "    data =  data.astype(np.float16)\n",
    "    file = \"/path/to/save/%s.npy\" %(i.split('/')[-1].split('.')[0])\n",
    "    np.save(file, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d476b0-0f44-4add-ab60-87a18afbed65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#4feat\n",
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "tot = glob.glob(\"/path/to/saved/*.pickle\")\n",
    "\n",
    "def make_np(i, dic):\n",
    "    #print(i)\n",
    "    with open(file=i, mode='rb') as f:\n",
    "        chrgecar = pickle.load(f)\n",
    "    chgcar = chrgecar\n",
    "    grid_points = get_grid_points(chgcar)\n",
    "    cartesian_points = grid_points_to_cartesian(chgcar.structure.lattice, grid_points)\n",
    "    key = list(chrgecar.spin_data.keys())\n",
    "    total_data = chgcar.data['total'].flatten()/dic[i.split('/')[-1].split('.')[0]]['vol']\n",
    "    total_data1 = chgcar.data['diff'].flatten()/dic[i.split('/')[-1].split('.')[0]]['vol']\n",
    "    total_data2 = chgcar.spin_data[key[0]].flatten()/dic[i.split('/')[-1].split('.')[0]]['vol']\n",
    "    total_data3 = chgcar.spin_data[key[1]].flatten()/dic[i.split('/')[-1].split('.')[0]]['vol']\n",
    "    data = np.concatenate((cartesian_points, np.expand_dims(total_data, axis=1), \n",
    "                           np.expand_dims(total_data1, axis=1), np.expand_dims(total_data2, axis=1),\n",
    "                           np.expand_dims(total_data3, axis=1)), axis=1)\n",
    "    data =  data.astype(np.float16)\n",
    "    #file = \"/path/to/save/%s.npy\" %(i.split('/')[-1].split('.')[0])\n",
    "    #np.save(file, data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37eccb-86fd-45b1-aa28-fcc603a09b87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tot:\n",
    "    make_np(i, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dce79e-5a73-4039-8d05-fd1564e01b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import torch_points3d.core.data_transform as T3D\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "#pre_transform = T.Compose([T.NormalizeScale()])\n",
    "pt_data = []\n",
    "pre_transform1 = T.Compose([T3D.GridSampling3D(0.25,  quantize_coords=True, verbose=True)])\n",
    "tot = glob.glob(\"/path/to/saved/*.npy\")\n",
    "for idx_batch in tqdm(range(len(tot))):\n",
    "        data = np.load(tot[idx_batch])\n",
    "        point_cloud = torch.from_numpy(data).to(dtype=torch.float32)\n",
    "        point_cloud = point_cloud[point_cloud[:, 3] > 0]\n",
    "        sampled_point_cloud = point_cloud\n",
    "        pos = sampled_point_cloud[:, :3]\n",
    "        t = sampled_point_cloud[:, 3:]/dic[tot[idx_batch].split('/')[-1].split('.')[0]]\n",
    "        tar = torch.tensor([target], dtype=torch.int32)\n",
    "        data = pre_transform1(Data(pos=pos, x=t))\n",
    "        torch.save(data, '/path/to/save/mp_cart_rand_pt/' + i.split('/')[-1].split('.')[0] + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fc7f3-91c1-4768-abb1-c92e02cf78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
