{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f3231-7ae1-4cf0-915c-b2555e9f91f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import MinkowskiEngine as ME\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7842f-7b9a-4995-b076-94d6399a58d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load ICSD label dict with file_name_index\n",
    "import pickle\n",
    "with open(\"/home/lumi_hgx/shkim/xrd_embbeding/ICSD_labels.pickle\" , \"rb\") as f:\n",
    "    dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8df08-bf3d-4046-bdd0-c3f9f7145895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# laod sampled point cloud file to make data list \n",
    "# in case 230 class use this code\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "data_list = []\n",
    "pt_list = glob.glob(\"/home/ssd1/shkim/icsd_cart_rand_pt/*.pt\")\n",
    "for i in tqdm(pt_list):\n",
    "    data = torch.load(i)\n",
    "    data.tar = dic[i.split('/')[-1].split('.')[0]]\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcee5e-c6f7-44ad-b2bd-1cbd06c3add9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if data list make to training 7 class\n",
    "# run previous cell and run this cell\n",
    "for i in data_list:\n",
    "    if i.tar == 1 or i.tar== 2:\n",
    "        i.tar = torch.tensor(0, dtype=torch.int32)\n",
    "    elif i.tar>= 3 and i.tar<= 15:\n",
    "        i.tar = torch.tensor(1, dtype=torch.int32)\n",
    "    elif i.tar>= 16 and i.tar<= 74:\n",
    "        i.tar = torch.tensor(2, dtype=torch.int32)\n",
    "    elif i.tar>= 75 and i.tar<= 142:\n",
    "        i.tar = torch.tensor(3, dtype=torch.int32)\n",
    "    elif i.tar>= 143 and i.tar<= 167:\n",
    "        i.tar = torch.tensor(4, dtype=torch.int32)\n",
    "    elif i.tar>= 168 and i.tar<= 194:\n",
    "        i.tar = torch.tensor(5, dtype=torch.int32)\n",
    "    elif i.tar>= 195 and i.tar<= 230:\n",
    "        i.tar = torch.tensor(6, dtype=torch.int32)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff6f36-53c1-4523-94b6-d042a59093fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data list make to training 101 class\n",
    "# run previous cell of load pt file and run this cell\n",
    "for i in data_list:\n",
    "\n",
    "    if i.tar + 1 in (1,2):\n",
    "        i.tar = 1            \n",
    "    elif i.tar + 1 in (3,6,10):\n",
    "        i.tar = 2            \n",
    "    elif i.tar + 1 in (4,11):\n",
    "        i.tar = 3  \n",
    "    elif i.tar + 1 in (5,8,12):\n",
    "        i.tar = 4  \n",
    "    elif i.tar + 1 in (7,13):\n",
    "        i.tar = 5          \n",
    "    elif i.tar + 1 in (9,15):\n",
    "        i.tar = 6            \n",
    "    elif i.tar + 1 == 14:\n",
    "        i.tar = 7  \n",
    "    elif i.tar + 1 in (16,25,47):\n",
    "        i.tar = 8  \n",
    "    elif i.tar + 1 == 17:\n",
    "        i.tar = 9            \n",
    "    elif i.tar + 1 == 18:\n",
    "        i.tar = 10            \n",
    "    elif i.tar + 1 == 19:\n",
    "        i.tar = 11  \n",
    "    elif i.tar + 1 == 20:\n",
    "        i.tar = 12  \n",
    "    elif i.tar + 1 in (21,35,38,65):\n",
    "        i.tar = 13            \n",
    "    elif i.tar + 1 in (22,42,69):\n",
    "        i.tar = 14            \n",
    "    elif i.tar + 1 in (23,24,44,71):\n",
    "        i.tar = 15  \n",
    "    elif i.tar + 1 in (26,28,51):\n",
    "        i.tar = 16  \n",
    "    elif i.tar + 1 in (27,49):\n",
    "        i.tar = 17            \n",
    "    elif i.tar + 1 in (29,57):\n",
    "        i.tar = 18            \n",
    "    elif i.tar + 1 in (30,53):\n",
    "        i.tar = 19            \n",
    "    elif i.tar + 1 in (31,59):\n",
    "        i.tar = 20  \n",
    "    elif i.tar + 1 in (32,55):\n",
    "        i.tar = 21  \n",
    "    elif i.tar + 1 in (33,62):\n",
    "        i.tar = 22  \n",
    "    elif i.tar + 1 in (34,58):\n",
    "        i.tar = 23            \n",
    "    elif i.tar + 1 in (36,40,63):\n",
    "        i.tar = 24            \n",
    "    elif i.tar + 1 in (37,66):\n",
    "        i.tar = 25  \n",
    "    elif i.tar + 1 in (39,67):\n",
    "        i.tar = 26  \n",
    "    elif i.tar + 1 in (41,64):\n",
    "        i.tar = 27          \n",
    "    elif i.tar + 1 == 43:\n",
    "        i.tar = 28            \n",
    "    elif i.tar + 1 in (45,72):\n",
    "        i.tar = 29            \n",
    "    elif i.tar + 1 in (46,74):\n",
    "        i.tar = 30  \n",
    "    elif i.tar + 1 == 48:\n",
    "        i.tar = 31  \n",
    "    elif i.tar + 1 == 50:\n",
    "        i.tar = 32  \n",
    "    elif i.tar + 1 == 52:\n",
    "        i.tar = 33            \n",
    "    elif i.tar + 1 == 54:\n",
    "        i.tar = 34            \n",
    "    elif i.tar + 1 == 56:\n",
    "        i.tar = 35  \n",
    "    elif i.tar + 1 == 60:\n",
    "        i.tar = 36  \n",
    "    elif i.tar + 1 == 61:\n",
    "        i.tar = 37\n",
    "    elif i.tar + 1 == 68:\n",
    "        i.tar = 38            \n",
    "    elif i.tar + 1 == 70:\n",
    "        i.tar = 39            \n",
    "    elif i.tar + 1 == 73:\n",
    "        i.tar = 40  \n",
    "    elif i.tar + 1 in (75,81,83,89,99,111,115,123):\n",
    "        i.tar = 41        \n",
    "    elif i.tar + 1 in (76,78,91,95):\n",
    "        i.tar = 42  \n",
    "    elif i.tar + 1 in (77,84,93):\n",
    "        i.tar = 43            \n",
    "    elif i.tar + 1 in (79,82,87,97,107,119,121,139):\n",
    "        i.tar = 44            \n",
    "    elif i.tar + 1 in (80,98):\n",
    "        i.tar = 45  \n",
    "    elif i.tar + 1 in (85,129):\n",
    "        i.tar = 46  \n",
    "    elif i.tar + 1 == 86:\n",
    "        i.tar = 47\n",
    "    elif i.tar + 1 == 88:\n",
    "        i.tar = 48            \n",
    "    elif i.tar + 1 in (90,113):\n",
    "        i.tar = 49            \n",
    "    elif i.tar + 1 in (92,96):\n",
    "        i.tar = 50  \n",
    "    elif i.tar + 1 == 94:\n",
    "        i.tar = 51        \n",
    "    elif i.tar + 1 in (100,117,127):\n",
    "        i.tar = 52  \n",
    "    elif i.tar + 1 in (101,116,132):\n",
    "        i.tar = 53            \n",
    "    elif i.tar + 1 in (102,118,136):\n",
    "        i.tar = 54            \n",
    "    elif i.tar + 1 in (103,124):\n",
    "        i.tar = 55  \n",
    "    elif i.tar + 1 in (104,128):\n",
    "        i.tar = 56  \n",
    "    elif i.tar + 1 in (105,112,131):\n",
    "        i.tar = 57\n",
    "    elif i.tar + 1 in (106,135):\n",
    "        i.tar = 58            \n",
    "    elif i.tar + 1 in (108,120,140):\n",
    "        i.tar = 59            \n",
    "    elif i.tar + 1 in (109,122):\n",
    "        i.tar = 60  \n",
    "    elif i.tar + 1 == 110:\n",
    "        i.tar = 61  \n",
    "    elif i.tar + 1 == 114:\n",
    "        i.tar = 62  \n",
    "    elif i.tar + 1 == 125:\n",
    "        i.tar = 63            \n",
    "    elif i.tar + 1 == 126:\n",
    "        i.tar = 64            \n",
    "    elif i.tar + 1 == 130:\n",
    "        i.tar = 65  \n",
    "    elif i.tar + 1 == 133:\n",
    "        i.tar = 66  \n",
    "    elif i.tar + 1 == 134:\n",
    "        i.tar = 67\n",
    "    elif i.tar + 1 == 137:\n",
    "        i.tar = 68            \n",
    "    elif i.tar + 1 == 138:\n",
    "        i.tar = 69            \n",
    "    elif i.tar + 1 == 141:\n",
    "        i.tar = 70          \n",
    "    elif i.tar + 1 == 142:\n",
    "        i.tar = 71          \n",
    "    elif i.tar + 1 in (143,147,149,150,156,157,162,164):\n",
    "        i.tar = 72  \n",
    "    elif i.tar + 1 in (144,145,151,152,153,154):\n",
    "        i.tar = 73            \n",
    "    elif i.tar + 1 in (146,148,155,160,166):\n",
    "        i.tar = 74            \n",
    "    elif i.tar + 1 in (158,165):\n",
    "        i.tar = 75  \n",
    "    elif i.tar + 1 in (159,163):\n",
    "        i.tar = 76  \n",
    "    elif i.tar + 1 in (161,167):\n",
    "        i.tar = 77\n",
    "    elif i.tar + 1 in (168,174,175,177,183,187,189,191):\n",
    "        i.tar = 78            \n",
    "    elif i.tar + 1 in (169,170,178,179):\n",
    "        i.tar = 79            \n",
    "    elif i.tar + 1 in (171,172,180,181):\n",
    "        i.tar = 80    \n",
    "    elif i.tar + 1 in (173,176,182):\n",
    "        i.tar = 81          \n",
    "    elif i.tar + 1 in (184,192):\n",
    "        i.tar = 82  \n",
    "    elif i.tar + 1 in (185,188,193):\n",
    "        i.tar = 83            \n",
    "    elif i.tar + 1 in (186,190,194):\n",
    "        i.tar = 84            \n",
    "    elif i.tar + 1 in (195,200,207,215,221):\n",
    "        i.tar = 85  \n",
    "    elif i.tar + 1 in (196,202,209,216,225):\n",
    "        i.tar = 86  \n",
    "    elif i.tar + 1 in (197,199,204,211,217,229):\n",
    "        i.tar = 87\n",
    "    elif i.tar + 1 in (198,208):\n",
    "        i.tar = 88            \n",
    "    elif i.tar + 1 in (201,224):\n",
    "        i.tar = 89            \n",
    "    elif i.tar + 1 in (203,227):\n",
    "        i.tar = 90          \n",
    "    elif i.tar + 1 == 205:\n",
    "        i.tar = 91          \n",
    "    elif i.tar + 1 == 206:\n",
    "        i.tar = 92  \n",
    "    elif i.tar + 1 == 210:\n",
    "        i.tar = 93            \n",
    "    elif i.tar + 1 in (212,213):\n",
    "        i.tar = 94            \n",
    "    elif i.tar + 1 == 214:\n",
    "        i.tar = 95  \n",
    "    elif i.tar + 1 in (218,223):\n",
    "        i.tar = 96  \n",
    "    elif i.tar + 1 in (219,226):\n",
    "        i.tar = 97\n",
    "    elif i.tar + 1 == 220:\n",
    "        i.tar = 98            \n",
    "    elif i.tar + 1 == 222:\n",
    "        i.tar = 99            \n",
    "    elif i.tar + 1 == 228:\n",
    "        i.tar = 100  \n",
    "    elif i.tar + 1 == 230:\n",
    "        i.tar = 101 \n",
    "        \n",
    "for i in data_list:\n",
    "    i.tar = i.tar - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61974d-ad33-4cc1-92cb-1ee759337a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in case of data point value with inf, run this  cell\n",
    "datall = []\n",
    "for i in tqdm(data_list):\n",
    "    if torch.isinf(i.x.max()) == False:\n",
    "        datall.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50fd7d-0eb1-44fc-b6ae-6acc0491b69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, test_files = train_test_split(datall, test_size=0.1, random_state=7)\n",
    "train_files, val_files = train_test_split(data_train, test_size=0.13333, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159cc5b-7c0a-4ae0-bbe3-ad9bb6dd92a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def minkowski_collate_fn(list_data):\n",
    "    coordinates_batch, features_batch, labels_batch = ME.utils.sparse_collate(\n",
    "        [d.pos for d in list_data],\n",
    "        [torch.cat((d.pos,d.x), 1) for d in list_data],\n",
    "        [d.y.item() for d in list_data],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "    return {\n",
    "        \"coordinates\": coordinates_batch,\n",
    "        \"features\": features_batch,\n",
    "        \"labels\": labels_batch,\n",
    "    }\n",
    "\n",
    "\n",
    "def stack_collate_fn(list_data):\n",
    "    coordinates_batch, features_batch, labels_batch = (\n",
    "        torch.stack([torch.cat((d.pos,d.x), 1) for d in list_data]),\n",
    "        torch.stack([d.x for d in list_data]),\n",
    "        torch.cat([torch.tensor([d.tar]) for d in list_data]),\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"coordinates\": coordinates_batch,\n",
    "        \"features\": features_batch,\n",
    "        \"labels\": labels_batch,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe2798-0ba2-4586-9d83-1bd23185ff8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "num_epochs = 3000\n",
    "is_minknet = False\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "train_files, \n",
    "batch_size=1, \n",
    "shuffle=True, \n",
    "num_workers=0,\n",
    "collate_fn=minkowski_collate_fn if is_minknet else stack_collate_fn, \n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "val_files, \n",
    "batch_size=1, \n",
    "shuffle=False, \n",
    "num_workers=0,  \n",
    "collate_fn=minkowski_collate_fn if is_minknet else stack_collate_fn,\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "test_files, \n",
    "batch_size=1, \n",
    "shuffle=False, \n",
    "num_workers=0,  \n",
    "collate_fn=minkowski_collate_fn if is_minknet else stack_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169cab7-fcb2-4cb1-9067-690d4bd09544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channel, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, out_channel)\n",
    "        # 인스턴스 정규화, 그룹 정규화 또는 레이어 정규화를 사용\n",
    "        self.norm1 = nn.GroupNorm(32, 64)  # 예시: 그룹 정규화\n",
    "        self.norm2 = nn.GroupNorm(32, 128)\n",
    "        self.norm3 = nn.GroupNorm(32, 1024)\n",
    "        self.norm4 = nn.LayerNorm(512)  # 예시: 레이어 정규화\n",
    "        self.norm5 = nn.LayerNorm(256)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.norm1(self.conv1(x)))\n",
    "        x = F.relu(self.norm2(self.conv2(x)))\n",
    "        x = F.relu(self.norm3(self.conv3(x)))\n",
    "        # 전역 최대 풀링 적용\n",
    "        x = torch.max(x, 2, keepdim=False)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.norm4(self.fc1(x)))\n",
    "        x = F.relu(self.norm5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8157c36-ca89-4849-8b72-9b565cf8d6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = PointNet(in_channel=4, out_channel=7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cbe05-f71f-47e4-9da1-fe806a3dff2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=0\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, model, optimizer\n",
    "    ):\n",
    "        if current_valid_loss > self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, f'/home/ssd1/shkim/logs35/icsd_7class_point_rand/best_model.pth')\n",
    "\n",
    "save_best_model = SaveBestModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb416b-0184-4c82-a612-e72c4483f3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=f'/home/ssd1/shkim/logs35/icsd_7class_point_rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d811ce-8a38-4d67-b19d-0ae909cba54d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_input_batch(batch, is_minknet, device=\"cuda\", quantization_size=0.05):\n",
    "    if is_minknet:\n",
    "        batch[\"coordinates\"][:, 1:] = batch[\"coordinates\"][:, 1:] / quantization_size\n",
    "        return ME.TensorField(\n",
    "            coordinates=batch[\"coordinates\"],\n",
    "            features=batch[\"features\"],\n",
    "            device=device,\n",
    "        )\n",
    "    else:\n",
    "        return batch[\"coordinates\"].permute(0, 2, 1).to(device)\n",
    "\n",
    "def criterion(pred, labels, smoothing=True):\n",
    "    \"\"\"Calculate cross entropy loss, apply label smoothing if needed.\"\"\"\n",
    "\n",
    "    labels = labels.contiguous().view(-1)\n",
    "    if smoothing:\n",
    "        eps = 0.2\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, labels.view(-1, 1).to(torch.int64), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "        log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
    "    else:\n",
    "        loss = F.cross_entropy(pred, labels, reduction=\"mean\")\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a4d60-b22a-44b1-a00c-5b2aabfc7bb9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.auto import tqdm\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3000):\n",
    "    # Train model\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_acc_t = 0\n",
    "    net.train()\n",
    "    n = 1\n",
    "  \n",
    "    # virtual batch setting\n",
    "    virtual_batch_size = 32\n",
    "    accumulation_steps = virtual_batch_size // 1  \n",
    "    optimizer.zero_grad()\n",
    "    accumulation_counter = 0\n",
    "\n",
    "    with tqdm(zip(train_dataloader), unit=\"batch\", total=len(train_dataloader)) as tepoch:\n",
    "        for batch_data in tepoch:\n",
    "\n",
    "            input = create_input_batch(\n",
    "                batch_data[0], is_minknet, device=device, quantization_size=config.voxel_size\n",
    "            )\n",
    "            # Forward pass\n",
    "            logits = net(input)\n",
    "            loss = torch.nn.functional.nll_loss(logits, batch_data[0][\"labels\"].to(torch.long).cuda())\n",
    "\n",
    "            loss.backward()\n",
    "            # virtual batch gradient update\n",
    "            accumulation_counter += 1\n",
    "            if accumulation_counter % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            labels_again = torch.argmax(logits, dim=1)\n",
    "            correct = torch.eq(batch_data[0][\"labels\"].cuda(), labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "            train_acc_t += (correct / len(logits)) * 100 \n",
    "            tepoch.set_postfix(total_loss=train_loss/n, batch_loss=loss.item(), train_acc = train_acc_t/n)\n",
    "            n = n + 1\n",
    "            #last gradient update on rest batch\n",
    "        if accumulation_counter % accumulation_steps != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc_t /= len(train_dataloader)\n",
    "\n",
    "        print(f\" Train Loss: loss {train_loss:.4f}\")\n",
    "        print(f\" Train acc: acc {train_acc_t:.4f}\")\n",
    "        writer.add_scalar(f\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(f\"acc/train\", train_acc_t, epoch)\n",
    "        \n",
    "\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_acc_t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(test_dataloader)):\n",
    "            input = create_input_batch(\n",
    "                batch_data, is_minknet, device=device, quantization_size=config.voxel_size\n",
    "            )\n",
    "            logits = net(input)\n",
    "\n",
    "\n",
    "            loss = torch.nn.functional.nll_loss(logits, batch_data[\"labels\"].to(torch.long).cuda())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            labels_again = torch.argmax(logits, dim=1)\n",
    "            correct = torch.eq(batch_data[\"labels\"].cuda(), labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "            val_acc_t += (correct / len(logits)) * 100 \n",
    "\n",
    "    val_loss /= len(test_dataloader)\n",
    "    val_acc_t /= len(test_dataloader)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    save_best_model(val_acc_t, epoch, net, optimizer)\n",
    "\n",
    "    writer.add_scalars(\"every_1_epoch\", {\n",
    "                            \"Loss/train_2\":train_loss,\n",
    "                            \"acc/train_2\":train_acc_t,\n",
    "                            \"Loss/val_2\":val_loss,\n",
    "                            \"acc/val_2\":val_acc_t,\n",
    "                            \"learning_Rate\":scheduler.optimizer.param_groups[0]['lr']},epoch)\n",
    "\n",
    "    print(f\"Validation Loss:  loss {val_loss:.4f}\")\n",
    "    print(f\"Validation acc:  acc {val_acc_t:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a4a69-4253-432d-a66f-4974fb400ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "val_acc_t = 0\n",
    "for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "    input = create_input_batch(\n",
    "        batch_data, is_minknet, device=device, quantization_size=config.voxel_size\n",
    "    )\n",
    "    logits = net(input)\n",
    "\n",
    "\n",
    "    loss = torch.nn.functional.nll_loss(logits, batch_data[\"labels\"].to(torch.long).cuda())\n",
    "\n",
    "    val_loss += loss.item()\n",
    "    labels_again = torch.argmax(logits, dim=1)\n",
    "    correct = torch.eq(batch_data[\"labels\"].cuda(), labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    val_acc_t += (correct / len(logits)) * 100 \n",
    "\n",
    "val_loss /= len(val_dataloader)\n",
    "val_acc_t /= len(val_dataloader)\n",
    "scheduler.step(val_loss)\n",
    "\n",
    "save_best_model(val_acc_t, epoch, net, optimizer)\n",
    "\n",
    "writer.add_scalars(\"every_1_epoch\", {\n",
    "                        \"Loss/train_2\":train_loss,\n",
    "                        \"acc/train_2\":train_acc_t,\n",
    "                        \"Loss/val_2\":val_loss,\n",
    "                        \"acc/val_2\":val_acc_t,\n",
    "                        \"learning_Rate\":scheduler.optimizer.param_groups[0]['lr']},epoch)\n",
    "\n",
    "print(f\"Validation Loss:  loss {val_loss:.4f}\")\n",
    "print(f\"Validation acc:  acc {val_acc_t:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafb2da-2fdf-40e1-ad31-1358bc355807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a85d6-60b4-451c-bfe2-ed1ecc26c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained weight\n",
    "net.load_state_dict(torch.load('/home/ssd1/shkim/logs21/icds7class_pointnet/best_model.pth')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fd6e4-1e0f-4922-890d-1577a62a429d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "val_acc_t = 0\n",
    "pred_label = []\n",
    "real_label = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "        input = create_input_batch(\n",
    "            batch_data, is_minknet, device=device, quantization_size=config.voxel_size\n",
    "        )\n",
    "        logits = net(input)\n",
    "\n",
    "\n",
    "        loss = torch.nn.functional.nll_loss(logits, batch_data[\"labels\"].to(torch.long).cuda())\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        labels_again = torch.argmax(logits, dim=1)\n",
    "        pred_label.append(labels_again.item())\n",
    "        real_label.append(batch_data[\"labels\"].item())\n",
    "        correct = torch.eq(batch_data[\"labels\"].cuda(), labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "        val_acc_t += (correct / len(logits)) * 100 \n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_acc_t /= len(val_dataloader)\n",
    "    #scheduler.step(val_loss)\n",
    "    print(f\"Validation Loss:  loss {val_loss:.4f}\")\n",
    "    print(f\"Validation acc:  acc {val_acc_t:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1de95-d5d0-4053-8007-ff1d1a8c6e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(accuracy_score(real_label, pred_label))\n",
    "print(f1_score(real_label, pred_label, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceaad81-3fbc-4a09-a4b4-cfe3a47a5fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb21af5-15a7-4944-8349-605ef3291536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(real_label, pred_label, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9e81f-6698-46d5-8633-2a9c8267dce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9ce24-53c8-4108-a3d1-f7d29fa84b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d045a-7259-4d78-a211-27953678d81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384aa04-527a-47dc-915e-29f104c7e0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4a642-465e-4d88-b4d7-c06da1072fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1a110-6ea1-43d8-9440-bc7df260cd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c64565-9725-4c48-8140-35ab04b7cbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe4868-a747-41ec-8c92-fce99ff643d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1d39a-97aa-4eb0-99d2-ec4f4222fcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6243e8-8882-44ad-92d4-738bd09a0f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a252a-6f32-4c9d-a72e-def936b1d6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pc_torch]",
   "language": "python",
   "name": "conda-env-pc_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
