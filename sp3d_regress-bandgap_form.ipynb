{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f24415-1601-4ce6-8b75-eda370994485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "from tqdm.std import tqdm\n",
    "import torch_points3d.core.data_transform as T3D\n",
    "import torch_geometric.transforms as T\n",
    "import torch.utils.data as data\n",
    "from torch_geometric.data import Batch\n",
    "from torch_points3d.datasets.batch import SimpleBatch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_geometric.data import Batch, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef9b0d-40b7-49ba-a976-65032221bb53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yaml_config = \"\"\"\n",
    "conv_type: \"SPARSE\"\n",
    "define_constants:\n",
    "    in_feat: 128\n",
    "    block: ResBlock # Can be any of the blocks in modules/SparseConv3d/modules.py\n",
    "down_conv:\n",
    "    module_name: ResNetDown\n",
    "    block: block\n",
    "    N: [0, 2, 3, 4, 3]\n",
    "    down_conv_nn:\n",
    "        [\n",
    "            [FEAT, in_feat],\n",
    "            [in_feat, in_feat],\n",
    "            [in_feat, 2*in_feat],\n",
    "            [2*in_feat, 4*in_feat],\n",
    "            [4*in_feat, 8*in_feat],\n",
    "        ]\n",
    "    kernel_size: [3, 3, 3, 3, 3]\n",
    "    stride: [1, 2, 2, 2, 2]\n",
    "innermost:\n",
    "    module_name: GlobalBaseModule\n",
    "    activation:\n",
    "        name: LeakyReLU\n",
    "        negative_slope: 0.2\n",
    "    aggr: \"max\"\n",
    "    nn: [8*in_feat, 8*in_feat]\n",
    "\"\"\" \n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "params = OmegaConf.create(yaml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2e257-9094-42b8-8919-f34f3d94a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_points3d.applications.sparseconv3d import SparseConv3d\n",
    "from torch.nn import functional as F\n",
    "class spConvregress(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        #if use 1feat- input_nc=1, use 4feat - input_nc=4\n",
    "        self.encoder = SparseConv3d(\"encoder\", input_nc=1, num_layers=4, config=params) # minkowski by default\n",
    "        self.linear = torch.nn.Linear(8*128, 4*128, bias=True)\n",
    "        self.linear1 = torch.nn.Linear(4*128, 2*128, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(2*128, 128, bias=True)\n",
    "        self.linear3 = torch.nn.Linear(128, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(8*128)\n",
    "        self.bn1 = nn.BatchNorm1d(4*128)\n",
    "        self.bn2 = nn.BatchNorm1d(2*128)\n",
    "        self.bn3 = nn.BatchNorm1d(1*128)\n",
    "    def forward(self, data):\n",
    "        # Set labels for the tracker\n",
    "        \n",
    "        # Forward through the network\n",
    "        data_out = self.encoder(data)\n",
    "        self.output = F.relu(self.bn(data_out.x.squeeze()))\n",
    "        self.output =  F.relu(self.bn1(self.linear(self.output)))\n",
    "        self.output =  F.relu(self.bn2(self.linear1(self.output)))\n",
    "        self.output =  F.relu(self.bn3(self.linear2(self.output)))\n",
    "        self.output =  F.relu(self.linear3(self.output))\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5daa6e-53db-41d9-880f-5ee4ce236409",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = spConvregress().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3945aa-d8b5-4b10-aacd-9683db9450de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893ddcd-93bd-42b9-bf1e-21deee043ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=f'/path/to/save/sp3_convcell_band_super')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cee44-7e1c-444a-8d06-2884cfac30f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"mp_id_data.json\", \"r\") as f:\n",
    "    dic = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd998c40-5d1d-4780-8624-c513409909ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "pt_list = glob.glob('/path/to/pt/files/*.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d70a6-b027-4c78-a8b1-fdf5d87955b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677fb01-0a40-438a-b8e9-2eecdbcf9a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#in case of bandgap energy\n",
    "datal = []\n",
    "for i in tqdm(pt_list):\n",
    "    data = torch.load(i)\n",
    "    data.x = data.x[:, 0].view(-1,1)\n",
    "    data.tar = torch.tensor(dic[i.split('/')[-1].split('.')[0]['bandgap']], dtype=torch.float32)\n",
    "    datal.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fab393-4357-4d9b-bced-69fc3c2f16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case of formation energy\n",
    "\n",
    "datal = []\n",
    "for i in tqdm(pt_list):\n",
    "    data = torch.load(i)\n",
    "    data.x = data.x[:, 0].view(-1,1)\n",
    "    data.tar = torch.tensor(dic[i.split('/')[-1].split('.')[0]['formationE']], dtype=torch.float32)\n",
    "    datal.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aafde9-3dda-487d-8ed4-3f54e90f3d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e857df9-20bc-4c35-b213-a89087bdf0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train, test_files = train_test_split(data_list, test_size=0.1, random_state=1)\n",
    "train_files, val_files = train_test_split(data_train, test_size=0.13333, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3b493-6d36-4907-90b6-6cb5428b9d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 3000\n",
    "\n",
    "collate_function = lambda datalist: Batch.from_data_list(datalist)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "train_files, \n",
    "batch_size=32, \n",
    "shuffle=True, \n",
    "num_workers=0,\n",
    "collate_fn=collate_function, pin_memory = True , \n",
    ")\n",
    "\n",
    "collate_function = lambda datalist: Batch.from_data_list(datalist)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "val_files, \n",
    "batch_size=32, \n",
    "shuffle=False, \n",
    "num_workers=0,  \n",
    "collate_fn=collate_function, pin_memory = True, #sampler=val_sampler\n",
    ")\n",
    "import torch.nn as nn\n",
    "\n",
    "#model = spConvregress().cuda()\n",
    "\n",
    "\n",
    "collate_function = lambda datalist: Batch.from_data_list(datalist)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "test_files, \n",
    "batch_size=32, \n",
    "shuffle=False, \n",
    "num_workers=0,  \n",
    "collate_fn=collate_function, pin_memory = True, #sampler=val_sampler\n",
    ")\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78c55f-90bb-454d-b353-d3f4dba56a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=10\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, model, optimizer\n",
    "    ):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, f'/home/ssd1/shkim/logs30/sp3_convcell_band_super/best_model.pth')\n",
    "\n",
    "save_best_model = SaveBestModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b779fc-fbb8-4da1-b432-c70702e0c34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33c52d-95ee-4ab8-9755-cc3cceac2f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c98b05-111b-4f95-b11c-bec382438124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34142828-48d5-492b-a65c-883f64a736f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "loss_function = torch.nn.L1Loss().cuda()\n",
    "for epoch in range(3000):\n",
    "     train_loss = 0.0\n",
    "     train_total = 0\n",
    "     train_mae = 0\n",
    "     model.train()\n",
    "     n = 1\n",
    "     with tqdm(train_dataloader, unit=\"batch\", total=len(train_dataloader)) as tepoch:\n",
    "        for batch_data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                batch_data = batch_data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                logits = model(batch_data)\n",
    "                loss = loss_function(logits.squeeze(), batch_data.tar2.squeeze())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                tepoch.set_postfix(total_mae_loss=train_loss/n, batch_loss=loss.item())\n",
    "                n = n + 1\n",
    "                \n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        print(f\"Train Loss: MAE {train_loss:.4f}\")\n",
    "        \n",
    "     model.eval()\n",
    "     val_loss = 0.0\n",
    "     val_correct = 0\n",
    "     val_total = 0\n",
    "     val_mae = 0\n",
    "     with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "\n",
    "            batch_data = batch_data.cuda()\n",
    "            logits = model(batch_data)\n",
    "            loss = loss_function(logits.squeeze(), batch_data.tar2.squeeze())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        save_best_model(val_loss, epoch, model, optimizer)\n",
    "\n",
    "        writer.add_scalars(\"every_1_epoch\", {\"Loss/train_2\":train_loss,\n",
    "                                \"Loss/val_2\":val_loss,\n",
    "                                \"learning_Rate\":scheduler.optimizer.param_groups[0]['lr']},epoch)\n",
    "\n",
    "        print(f\"Validation Loss:  MAE {val_loss:.4f}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e26a62-d4fe-477d-8bb7-4133710d84e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " model.eval()\n",
    " val_loss = 0.0\n",
    " val_correct = 0\n",
    " val_total = 0\n",
    " val_mae = 0\n",
    " with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "\n",
    "        batch_data = batch_data.cuda()\n",
    "        logits = model(batch_data)\n",
    "        loss = loss_function(logits.squeeze(), batch_data.tar.squeeze())\n",
    "\n",
    "        val_loss += loss.item()\n",
    "\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Validation Loss:  MAE {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac88b7a-da74-4f7e-9aed-e8a9c4a411c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pc_torch]",
   "language": "python",
   "name": "conda-env-pc_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
