{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f24415-1601-4ce6-8b75-eda370994485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "from tqdm.std import tqdm\n",
    "import torch_points3d.core.data_transform as T3D\n",
    "import torch_geometric.transforms as T\n",
    "import torch.utils.data as data\n",
    "from torch_geometric.data import Batch\n",
    "from torch_points3d.datasets.batch import SimpleBatch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_geometric.data import Batch, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef9b0d-40b7-49ba-a976-65032221bb53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yaml_config = \"\"\"\n",
    "conv_type: \"SPARSE\"\n",
    "define_constants:\n",
    "    in_feat: 128\n",
    "    block: ResBlock # Can be any of the blocks in modules/SparseConv3d/modules.py\n",
    "down_conv:\n",
    "    module_name: ResNetDown\n",
    "    block: block\n",
    "    N: [0, 1, 2, 2, 3]\n",
    "    down_conv_nn:\n",
    "        [\n",
    "            [FEAT, in_feat],\n",
    "            [in_feat, in_feat],\n",
    "            [in_feat, 2*in_feat],\n",
    "            [2*in_feat, 4*in_feat],\n",
    "            [4*in_feat, 8*in_feat],\n",
    "        ]\n",
    "    kernel_size: [3, 3, 3, 3, 3]\n",
    "    stride: [1, 2, 2, 2, 2]\n",
    "innermost:\n",
    "    module_name: GlobalBaseModule\n",
    "    activation:\n",
    "        name: LeakyReLU\n",
    "        negative_slope: 0.2\n",
    "    aggr: \"max\"\n",
    "    nn: [8*in_feat, 8*in_feat]\n",
    "\"\"\" \n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "params = OmegaConf.create(yaml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc7fad-8feb-4c2e-97ab-178b9bb6f020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_points3d.applications.sparseconv3d import SparseConv3d\n",
    "\n",
    "class spConvregress(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.encoder = SparseConv3d(\"encoder\", input_nc=1, num_layers=2, output_nc=230, config=params) # minkowski by default\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "    def forward(self, data):\n",
    "        # Set labels for the tracker\n",
    "        \n",
    "        # Forward through the network\n",
    "        data_out = self.encoder(data)\n",
    "        self.output = self.log_softmax(data_out.x.squeeze())\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075301c-6148-4d2b-9cb6-6b1d0203d072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = spConvregress().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5daa6e-53db-41d9-880f-5ee4ce236409",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893ddcd-93bd-42b9-bf1e-21deee043ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=f'/home/ssd1/shkim/logs35/icsd_230class_sp3_rand_128feat_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494a392-5519-4ed0-8632-ee4f879dc5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ICSD_labels.pickle\" , \"rb\") as f:\n",
    "    dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fc977-a025-4495-ad7c-b3ae6c8a0435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "data_list = []\n",
    "pt_list = glob.glob(\"/home/ssd1/shkim/icsd_cart_rand_pt/*.pt\")\n",
    "for i in tqdm(pt_list):\n",
    "    data = torch.load(i)\n",
    "    data.tar = dic[i.split('/')[-1].split('.')[0]] - 1 # if in order to use 7class and 101 class  comment on  -1\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fb914-b652-459c-869a-56a0d4c3f91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if data list make to training 7 class\n",
    "# run previous cell and run this cell\n",
    "for i in dic:\n",
    "    i.tar= dic[i]\n",
    "    if i.tar== 1 or i.tar== 2:\n",
    "        dic[i] = torch.tensor(0, dtype=torch.int32)\n",
    "    elif i.tar>= 3 and i.tar<= 15:\n",
    "        dic[i] = torch.tensor(1, dtype=torch.int32)\n",
    "    elif val_c>= 16 and i.tar<= 74:\n",
    "        dic[i] = torch.tensor(2, dtype=torch.int32)\n",
    "    elif i.tar>= 75 and i.tar<= 142:\n",
    "        dic[i] = torch.tensor(3, dtype=torch.int32)\n",
    "    elif val_c>= 143 and i.tar<= 167:\n",
    "        dic[i] = torch.tensor(4, dtype=torch.int32)\n",
    "    elif i.tar>= 168 and i.tar<= 194:\n",
    "        dic[i] = torch.tensor(5, dtype=torch.int32)\n",
    "    elif i.tar>= 195 and i.tar<= 230:\n",
    "        dic[i] = torch.tensor(6, dtype=torch.int32)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff24423-eb11-4678-9238-b8844b929d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data list make to training 101 class\n",
    "# run previous cell of load pt file and run this cell\n",
    "for i in data_list:\n",
    "\n",
    "    if i.tar + 1 in (1,2):\n",
    "        i.tar = 1            \n",
    "    elif i.tar + 1 in (3,6,10):\n",
    "        i.tar = 2            \n",
    "    elif i.tar + 1 in (4,11):\n",
    "        i.tar = 3  \n",
    "    elif i.tar + 1 in (5,8,12):\n",
    "        i.tar = 4  \n",
    "    elif i.tar + 1 in (7,13):\n",
    "        i.tar = 5          \n",
    "    elif i.tar + 1 in (9,15):\n",
    "        i.tar = 6            \n",
    "    elif i.tar + 1 == 14:\n",
    "        i.tar = 7  \n",
    "    elif i.tar + 1 in (16,25,47):\n",
    "        i.tar = 8  \n",
    "    elif i.tar + 1 == 17:\n",
    "        i.tar = 9            \n",
    "    elif i.tar + 1 == 18:\n",
    "        i.tar = 10            \n",
    "    elif i.tar + 1 == 19:\n",
    "        i.tar = 11  \n",
    "    elif i.tar + 1 == 20:\n",
    "        i.tar = 12  \n",
    "    elif i.tar + 1 in (21,35,38,65):\n",
    "        i.tar = 13            \n",
    "    elif i.tar + 1 in (22,42,69):\n",
    "        i.tar = 14            \n",
    "    elif i.tar + 1 in (23,24,44,71):\n",
    "        i.tar = 15  \n",
    "    elif i.tar + 1 in (26,28,51):\n",
    "        i.tar = 16  \n",
    "    elif i.tar + 1 in (27,49):\n",
    "        i.tar = 17            \n",
    "    elif i.tar + 1 in (29,57):\n",
    "        i.tar = 18            \n",
    "    elif i.tar + 1 in (30,53):\n",
    "        i.tar = 19            \n",
    "    elif i.tar + 1 in (31,59):\n",
    "        i.tar = 20  \n",
    "    elif i.tar + 1 in (32,55):\n",
    "        i.tar = 21  \n",
    "    elif i.tar + 1 in (33,62):\n",
    "        i.tar = 22  \n",
    "    elif i.tar + 1 in (34,58):\n",
    "        i.tar = 23            \n",
    "    elif i.tar + 1 in (36,40,63):\n",
    "        i.tar = 24            \n",
    "    elif i.tar + 1 in (37,66):\n",
    "        i.tar = 25  \n",
    "    elif i.tar + 1 in (39,67):\n",
    "        i.tar = 26  \n",
    "    elif i.tar + 1 in (41,64):\n",
    "        i.tar = 27          \n",
    "    elif i.tar + 1 == 43:\n",
    "        i.tar = 28            \n",
    "    elif i.tar + 1 in (45,72):\n",
    "        i.tar = 29            \n",
    "    elif i.tar + 1 in (46,74):\n",
    "        i.tar = 30  \n",
    "    elif i.tar + 1 == 48:\n",
    "        i.tar = 31  \n",
    "    elif i.tar + 1 == 50:\n",
    "        i.tar = 32  \n",
    "    elif i.tar + 1 == 52:\n",
    "        i.tar = 33            \n",
    "    elif i.tar + 1 == 54:\n",
    "        i.tar = 34            \n",
    "    elif i.tar + 1 == 56:\n",
    "        i.tar = 35  \n",
    "    elif i.tar + 1 == 60:\n",
    "        i.tar = 36  \n",
    "    elif i.tar + 1 == 61:\n",
    "        i.tar = 37\n",
    "    elif i.tar + 1 == 68:\n",
    "        i.tar = 38            \n",
    "    elif i.tar + 1 == 70:\n",
    "        i.tar = 39            \n",
    "    elif i.tar + 1 == 73:\n",
    "        i.tar = 40  \n",
    "    elif i.tar + 1 in (75,81,83,89,99,111,115,123):\n",
    "        i.tar = 41        \n",
    "    elif i.tar + 1 in (76,78,91,95):\n",
    "        i.tar = 42  \n",
    "    elif i.tar + 1 in (77,84,93):\n",
    "        i.tar = 43            \n",
    "    elif i.tar + 1 in (79,82,87,97,107,119,121,139):\n",
    "        i.tar = 44            \n",
    "    elif i.tar + 1 in (80,98):\n",
    "        i.tar = 45  \n",
    "    elif i.tar + 1 in (85,129):\n",
    "        i.tar = 46  \n",
    "    elif i.tar + 1 == 86:\n",
    "        i.tar = 47\n",
    "    elif i.tar + 1 == 88:\n",
    "        i.tar = 48            \n",
    "    elif i.tar + 1 in (90,113):\n",
    "        i.tar = 49            \n",
    "    elif i.tar + 1 in (92,96):\n",
    "        i.tar = 50  \n",
    "    elif i.tar + 1 == 94:\n",
    "        i.tar = 51        \n",
    "    elif i.tar + 1 in (100,117,127):\n",
    "        i.tar = 52  \n",
    "    elif i.tar + 1 in (101,116,132):\n",
    "        i.tar = 53            \n",
    "    elif i.tar + 1 in (102,118,136):\n",
    "        i.tar = 54            \n",
    "    elif i.tar + 1 in (103,124):\n",
    "        i.tar = 55  \n",
    "    elif i.tar + 1 in (104,128):\n",
    "        i.tar = 56  \n",
    "    elif i.tar + 1 in (105,112,131):\n",
    "        i.tar = 57\n",
    "    elif i.tar + 1 in (106,135):\n",
    "        i.tar = 58            \n",
    "    elif i.tar + 1 in (108,120,140):\n",
    "        i.tar = 59            \n",
    "    elif i.tar + 1 in (109,122):\n",
    "        i.tar = 60  \n",
    "    elif i.tar + 1 == 110:\n",
    "        i.tar = 61  \n",
    "    elif i.tar + 1 == 114:\n",
    "        i.tar = 62  \n",
    "    elif i.tar + 1 == 125:\n",
    "        i.tar = 63            \n",
    "    elif i.tar + 1 == 126:\n",
    "        i.tar = 64            \n",
    "    elif i.tar + 1 == 130:\n",
    "        i.tar = 65  \n",
    "    elif i.tar + 1 == 133:\n",
    "        i.tar = 66  \n",
    "    elif i.tar + 1 == 134:\n",
    "        i.tar = 67\n",
    "    elif i.tar + 1 == 137:\n",
    "        i.tar = 68            \n",
    "    elif i.tar + 1 == 138:\n",
    "        i.tar = 69            \n",
    "    elif i.tar + 1 == 141:\n",
    "        i.tar = 70          \n",
    "    elif i.tar + 1 == 142:\n",
    "        i.tar = 71          \n",
    "    elif i.tar + 1 in (143,147,149,150,156,157,162,164):\n",
    "        i.tar = 72  \n",
    "    elif i.tar + 1 in (144,145,151,152,153,154):\n",
    "        i.tar = 73            \n",
    "    elif i.tar + 1 in (146,148,155,160,166):\n",
    "        i.tar = 74            \n",
    "    elif i.tar + 1 in (158,165):\n",
    "        i.tar = 75  \n",
    "    elif i.tar + 1 in (159,163):\n",
    "        i.tar = 76  \n",
    "    elif i.tar + 1 in (161,167):\n",
    "        i.tar = 77\n",
    "    elif i.tar + 1 in (168,174,175,177,183,187,189,191):\n",
    "        i.tar = 78            \n",
    "    elif i.tar + 1 in (169,170,178,179):\n",
    "        i.tar = 79            \n",
    "    elif i.tar + 1 in (171,172,180,181):\n",
    "        i.tar = 80    \n",
    "    elif i.tar + 1 in (173,176,182):\n",
    "        i.tar = 81          \n",
    "    elif i.tar + 1 in (184,192):\n",
    "        i.tar = 82  \n",
    "    elif i.tar + 1 in (185,188,193):\n",
    "        i.tar = 83            \n",
    "    elif i.tar + 1 in (186,190,194):\n",
    "        i.tar = 84            \n",
    "    elif i.tar + 1 in (195,200,207,215,221):\n",
    "        i.tar = 85  \n",
    "    elif i.tar + 1 in (196,202,209,216,225):\n",
    "        i.tar = 86  \n",
    "    elif i.tar + 1 in (197,199,204,211,217,229):\n",
    "        i.tar = 87\n",
    "    elif i.tar + 1 in (198,208):\n",
    "        i.tar = 88            \n",
    "    elif i.tar + 1 in (201,224):\n",
    "        i.tar = 89            \n",
    "    elif i.tar + 1 in (203,227):\n",
    "        i.tar = 90          \n",
    "    elif i.tar + 1 == 205:\n",
    "        i.tar = 91          \n",
    "    elif i.tar + 1 == 206:\n",
    "        i.tar = 92  \n",
    "    elif i.tar + 1 == 210:\n",
    "        i.tar = 93            \n",
    "    elif i.tar + 1 in (212,213):\n",
    "        i.tar = 94            \n",
    "    elif i.tar + 1 == 214:\n",
    "        i.tar = 95  \n",
    "    elif i.tar + 1 in (218,223):\n",
    "        i.tar = 96  \n",
    "    elif i.tar + 1 in (219,226):\n",
    "        i.tar = 97\n",
    "    elif i.tar + 1 == 220:\n",
    "        i.tar = 98            \n",
    "    elif i.tar + 1 == 222:\n",
    "        i.tar = 99            \n",
    "    elif i.tar + 1 == 228:\n",
    "        i.tar = 100  \n",
    "    elif i.tar + 1 == 230:\n",
    "        i.tar = 101 \n",
    "        \n",
    "for i in data_list:\n",
    "    i.tar = i.tar - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26efd5-6c47-45e1-be0e-0965c2f268f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datall = []\n",
    "for i in tqdm(data_list):\n",
    "    if torch.isinf(i.x.max()) == False:\n",
    "        datall.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505695e4-f62d-4c1b-b52d-e7ad6581b5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train, test_files = train_test_split(datall, test_size=0.1, random_state=35)\n",
    "train_files, val_files = train_test_split(data_train, test_size=0.13333, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27a06c-b820-443c-80ee-ad6a5ba7dd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=0\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, model, optimizer\n",
    "    ):\n",
    "        if current_valid_loss > self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, f'/home/ssd1/shkim/logs35/icsd_230class_sp3_rand_128feat_4/best_model.pth')\n",
    "\n",
    "save_best_model = SaveBestModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2718c4-ae96-4c58-af09-317863282aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 3000\n",
    "\n",
    "collate_function = lambda datalist: Batch.from_data_list(datalist)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "train_files, \n",
    "batch_size=64, \n",
    "shuffle=True, \n",
    "num_workers=0,\n",
    "drop_last=True,\n",
    "collate_fn=collate_function, pin_memory = True , \n",
    ")\n",
    "\n",
    "collate_function = lambda datalist: Batch.from_data_list(datalist)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "val_files, \n",
    "batch_size=64, \n",
    "shuffle=False, \n",
    "num_workers=0,  \n",
    "collate_fn=collate_function, pin_memory = True, #sampler=val_sampler\n",
    ")\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "collate_function = lambda datalist: Batch.from_data_list(datalist)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "test_files, \n",
    "batch_size=64, \n",
    "shuffle=False, \n",
    "num_workers=0,  \n",
    "collate_fn=collate_function, pin_memory = True, #sampler=val_sampler\n",
    ")\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d2b81-08f8-41a4-9efa-e39be3e272eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.auto import tqdm\n",
    "optimizer = optim.Adam(model.parameters(), lr=7.8125e-06) #0.0005)\n",
    "#optimizer = optim.SGD(ddp_model.parameters(), lr=0.03, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "#loss_function =torch.nn.functional.nll_loss().cuda()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3000):\n",
    "    # Train model\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_acc_t = 0\n",
    "    model.train()\n",
    "    n = 1\n",
    "  \n",
    "\n",
    "    with tqdm(train_dataloader, unit=\"batch\", total=len(train_dataloader)) as tepoch:\n",
    "        for batch_data in tepoch:\n",
    "\n",
    "            batch_data = batch_data.cuda().to(torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_data)\n",
    "            loss = torch.nn.functional.nll_loss(logits.squeeze(), batch_data.tar.to(torch.long))\n",
    "\n",
    "            loss.backward()\n",
    "            # 가상 배치 크기에 도달하면, 그래디언트 업데이트\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            labels_again = torch.argmax(logits, dim=1)\n",
    "            correct = torch.eq(batch_data.tar, labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "            train_acc_t += (correct / len(logits)) * 100 \n",
    "            tepoch.set_postfix(total_loss=train_loss/n, batch_loss=loss.item(), train_acc = train_acc_t/n)\n",
    "            n = n + 1\n",
    "            \n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc_t /= len(train_dataloader)\n",
    "\n",
    "        print(f\" Train Loss: loss {train_loss:.4f}\")\n",
    "        print(f\" Train acc: acc {train_acc_t:.4f}\")\n",
    "        writer.add_scalar(f\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(f\"acc/train\", train_acc_t, epoch)\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_acc_t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "            batch_data = batch_data.cuda().to(torch.float32)\n",
    "            logits = model(batch_data)\n",
    "\n",
    "\n",
    "            loss = torch.nn.functional.nll_loss(logits.squeeze(), batch_data.tar.to(torch.long))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            labels_again = torch.argmax(logits, dim=1)\n",
    "            correct = torch.eq(batch_data.tar, labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "            val_acc_t += (correct / len(logits)) * 100 \n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_acc_t /= len(val_dataloader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        save_best_model(val_acc_t, epoch, model, optimizer)\n",
    "\n",
    "        writer.add_scalars(\"every_1_epoch\", {\n",
    "                                \"Loss/train_2\":train_loss,\n",
    "                                \"acc/train_2\":train_acc_t,\n",
    "                                \"Loss/val_2\":val_loss,\n",
    "                                \"acc/val_2\":val_acc_t,\n",
    "                                \"learning_Rate\":scheduler.optimizer.param_groups[0]['lr']},epoch)\n",
    "\n",
    "        print(f\"Validation Loss:  loss {val_loss:.4f}\")\n",
    "        print(f\"Validation acc:  acc {val_acc_t:.4f}\")\n",
    "        model_test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dce4d-c075-437f-9901-519975ed9484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c16e8-d5c0-43a3-8319-b0192a9917ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97ceea-a18c-4ef7-b6ba-c8b014fef834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/home/ssd1/shkim/logs22/mp_7class_sp3/best_model.pth\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca0002-0b62-4a6c-aed4-f822566bf8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "val_acc_t = 0\n",
    "real = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(tqdm(test_dataloader)):\n",
    "\n",
    "        batch_data = batch_data.cuda().to(torch.float32)\n",
    "        logits = model(batch_data)\n",
    "\n",
    "\n",
    "        loss = torch.nn.functional.nll_loss(logits.squeeze(), batch_data.tar.to(torch.long))\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        labels_again = torch.argmax(logits.squeeze(), dim=1)\n",
    "        pred.append(labels_again)\n",
    "        real.append(batch_data.tar)\n",
    "        correct = torch.eq(batch_data.tar, labels_again).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "        val_acc_t += (correct / len(logits)) * 100 \n",
    "\n",
    "    val_loss /= len(test_dataloader)\n",
    "    val_acc_t /= len(test_dataloader)\n",
    "    \n",
    "\n",
    "    print(f\"Validation Loss:  loss {val_loss:.4f}\")\n",
    "    print(f\"Validation acc:  acc {val_acc_t:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e7b2c-3411-4292-9bb2-bc1fc892a2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf47f8a-b1c7-4a23-96a4-26401a738cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_list = []\n",
    "for i in real:\n",
    "    for j in range(i.size()[0]):\n",
    "        real_list.append(i[j].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba33dc2-7c73-4f64-94f7-14fc5efb518a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in pred:\n",
    "    for j in range(i.size()[0]):\n",
    "        pred_list.append(i[j].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de40c3-8de9-4f17-911f-50990d0a5b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(accuracy_score(real_list, pred_list))\n",
    "print(f1_score(real_list, pred_list, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bf9d2-8c5b-4c74-b4cb-51e2dad0ea2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(real_list, pred_list, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac88b7a-da74-4f7e-9aed-e8a9c4a411c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pc_torch]",
   "language": "python",
   "name": "conda-env-pc_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
